\documentclass{anstrans}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{FluDAG and Other Implementations of the DAGMC Toolkit}
\author{Paul P.H. Wilson, Andrew Davis, Julie Zachman, Kerry L. Dunn}

\institute{University of Wisconsin-Madison, 1500 Engineering Dr, Madison, WI 53706}

\email{wilsonp@engr.wisc.edu}

% Optional disclaimer: remove this command to hide

%%%% packages and definitions (optional)
\usepackage{graphicx} % allows inclusion of graphics
\usepackage{epsfig}
\usepackage{booktabs} % nice rules (thick lines) for tables
\usepackage{microtype} % improves typography for PDF

\def\C++{%
    C\kern-.1667em\raise.30ex\hbox{\small{+\kern-.1667em+}}%
\spacefactor1000 }

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

The Direct Accelerated Geometry Monte Carlo (DAGMC) toolkit provides
an interface to the Mesh-Oriented datABase (MOAB) specialized for the
geometric operations of Monte Carlo radiation transport directly on
CAD-based geometries.  By taking full control of the geometric
operations, including ray tracing, point inclusion, and surface
determination, DAGMC allows an identical geometry representation to be
used in a variety of Monte Carlo physics solvers.

This work describes the application of the DAGMC toolkit to
Fluka\cite{fluka}, a Monte Carlo physics solver from CERN with support
for a wide array of particles at a broad range of energies.  The Fluka
implementation of DAGMC relies on previous work to integrate
GEANT4\cite{GEANT4} geometry capability with the Fluka physics solver,
known as FluGG\cite{flugg}.

In addition, we provide updates on efforts to integrate DAGMC with
other physics solvers including MCNP5\cite{mcnp5},
Tripoli4\cite{tripolo}, GEANT4, and SHIFT\cite{shift}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The DAGMC Toolkit}

The details of DAGMC have been described in other work, but are
summarized here for context.  A user generates a geometric description
of the problem using one of a variety of solid modeling software
packages and imports that geometry into Cubit\cite{cubit} for
pre-processing steps including assignment of materials and boundary
condition, and imprinting and merging.  This geometry file is used to
generate a facetted representation of the geometry that is stored in a
MOAB format, with precision adequate to guarantee reliable radiation
transport results\cite{snouffer}.  When loaded into a physics solver
modified with DAGMC, the material and boundary condition informaiton
is extracted and an oriented bounding box tree is generated to enable
accelerated geometry operations on this representation with $O(10^6)$
facets.  DAGMC allows simulation of complex geometries without
time-consuming translation to native geometric representations of the
physics solvers, with modest performance impact.  It also allows the
simulation of high-order surfaces that may not be supported by the
native geometric representation.

The DAGMC toolkit is comprised primarily of a small set of geometric
operations typical of Monte Carlo radiation transport: ray-tracing,
point inclusion, and normal determination.  The DAGMC interface also
includes methods for handling meta-data such as material assignment
and boundary conditions.  Integration with a physics solver typically
requires identifying all the geometry queries made by the phsyics
solver and replacing them with queries to the DAGMC interface.  In
addition, various approaches are necessary to manage the
initialziation phase of the simulation, depending on the physics
solver's initialization methods.  The primary physics solver used with
DAGMC has been MCNP5, providing unique computing capability for
analysis of shielding in fusion systems\cite{fusion3d} and criticality
deformed space nuclear energy systems\cite{nets}.

Integration of DAGMC with a particular physics solver is generally
easiest when that solver has already abstracted its geometry
interface.  There are different levels of sophistication for such
abstractions, depending on previous efforts to allow alternative
geometry representations.  In its simplest form, this abstraction is a
set of function names reserved for use by external geometry
representations.  In its most advanced form, this abstraction uses
langauge paradigms to define formal interface that can be implemented
by any geoemtry representation.  Handling geometry and metadata
initialization is often the most challenging aspect of integrating
DAGMC with a physics solver.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Fluka and FluGG}
\subsection{Fluka}
Fluka [ref] is a MC code provided by the Italian Institute for Nuclear
 Physics (INFN) and the Center for European Nuclear Research (CERN). The
  code is typically used for simulations in support of the facilities at   CERN, ATLAS, LHC etc, however is widely used for detector 
simuluations and 
\subsection{FluGG}
FluGG [ref] is the Fluka interface for Geant Geometry (FLUGG), it is suite
 of C++ wrapper routines that act as an interface between the exposed 
 parts of FLUKA subroutines and Geant4 libraries. The FLUKA team opened a
 number of interfaces to the FLUKA code around specific routines to allow the Physics routines of FLUKA to be used but with Geant4 geometry and
  therefore Geant geomeric queries, such as the distance to next surface 
  query, the volume of the other side of the next surface. The user simply 
  takes the C++ routines that represent the geometry, compile these to 
  object files, link against a limited subset of the Geant4 libraries and
   then link against the Fluka libraries, thus providing a custom executable
   that contains the users geometry. 
\section{FluDAG}
\subsection{Implementation \& Development}
The FluDAG development schema followed a similar implementation as FluGG using the exposed parts of the Fluka interface. C++ wrapper files were written for the fundamental queries that must be implemented;
\begin{itemize}
\item[g1wr]{Given the current ray volume ($V_i$), position ($x_i$,$y_i$,$z_i$), and direction ($\Omega_x$,$\Omega_y$,$\Omega_z$),return the distance to the next surface intersection.}
\item[lkwr]{Given the ray position ($x_i$,$y_i$,$z_i$), return the volume that position belong to.}	
\item[nrmlwr]{When crossing from volume ($V_i$) to volume ($V_j$), return
the vector between the particle direction and the surface normal.}
\end{itemize}
\subsection{Testing}
The testing of the code centered around the comparison between simulations performed using native Fluka geometries and the FluDAG equivalent. The models were built using native MCNP geometries; converted to CAD using mcnp2cad for Fludag and converted to Fluka by importing the MCNP geometry using the Flair [ref] interface.
\subsection*{USRTRACK Test Problems}
There were several analytic vacuum test problems to prove that results between Fluka and FluDAG are identical. The first test problems demonstrate that USRTRACK scores are producing indentical scores, the model composed of cubes of side 10.0 cm. A plane beam of neutrons start particles at an x coordinate of 0.0 cm. Setting the volume of each scorer to be 1.0 cubic cm, should result in a score of 10.0 for each tally. Both Fluka and FluDAG report a score of 9.999996 for every volume, showing that our implementation 
is correct.
\\
\\
Nested Spheres of incremental radius were created with radius 10 cm and were faceted 1.0e-4. This model was a better test 
\begin{tabular}{l|c|c|c}
Cell \# & Expected Score & Fluka  & FluDAG \\
\hline
1 & 10.0 & 9.999996 & 9.999209 \\
2 & 10.0 & 9.999996 & 10.00000 \\
3 & 10.0 & 9.999996 & 9.999995 \\
\end{tabular}

\subsection*{USRBDX Test problems}
\begin{figure}
	\begin{center}
		\epsfig{file=figs/bin_ratio.ps,width=.5\columnwidth,angle=-90}
		\epsfig{file=figs/bin_ratio_2.ps,width=.5\columnwidth,angle=-90}
		\caption{The neutron current crossing the surface bewteen volumes, in the 
		forward direction (upper) and at 80 degrees to the surface (lower)}
	\end{center}
\end{figure}
\section{Other DAGMC Implementations}

The DAGMC toolkit has already been integrated with a variety of
physics solvers.  The earliest development of DAGMC relied on source
code for MCNPX v2.x as testbed for capability development.  The focus
was shifted to MCNP5 and this has been the primary development
platform and the product, DAG-MCNP5, is used routinely for production
calculations in fusion neturonics applications.  The geometry
interface in MCNP5, written in FORTRAN90, is the least abstracted of
all the current implementations, requiring relatively intrusive source
code patches.  DAGMC will integrated with MCNP6 when its final source
code becomes available.

DAGMC has also been integrated with Tripoli4 \cite{tripoli4} from CEA
Saclay.  Due to prior abstraction of the geoemtry interface to support
the ROOT geometry representation, in addition to the native Tripoli
represenation, this integration was relatively straightforward.
Tripoli exposes a well defined \C++ interface for determining the
distance to the next surface, whether or not a point is inside a
volume, what volume is entered upon crossing a surface, and what the
normal is on a surface.

A recent effort to integrate DAGMC with GEANT4 has also proven
successful \cite{dag_geant4}.  GEANT4 has a highly abstracted geometry
interface, with a number of different implementations included with
the base GEANT4 package.  This implementation extends the standard
G4VSolid \C++ base class to create a DagSolid, with performance that
compares favorably to the G4TesselatedSolid class that provides a
similar capability.

The DAGMC toolkit has msot recently been integrated with the Shift
physics solver from ORNL.  Similar to other modern \C++ solvers, Shift
presents a well-defined geometry abstraction that facilitates
integration, including meta-data handling.  While unit testing has
demonstrated a successful implementation, final integration testing is
still underway.

\section{Conclusions and Future Work}

%%% insert conluding comments here

Having an indentical geometry representation available across a broad
set of physics solvers will enable a more robust comparison of the
physics methods and data libraries of each tool.  A future effort will
devise a suite of test problems that will be used with each of the
physics solvers and their results compared.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Acknowledgments}
This work is supported in part by NASA under contract XXXXX

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ans}
\bibliography{bibliography}
\end{document}

